Current approaches for atypical speech
- (1) 2 step fintuning
  1. finetune model to cohort
  2. finetune cohort-model to speaker
- (2) hypermodel
  - train hypermodel to provide LoRA weights on utterance level

Baseline
- need to compare approach (1) and (2)
  - cohort A, B
  - speaker S(A), T(A), U(B), V(B)
  - (1) model M1 for S 
  - (2) model M2 in A
  - model M3 not finetuned
  - M1 should outperform M2 for S but 
  - M2 should outperform M1 for T
  - M2 should also outperform M1 for U, V but that is not important (compare how good M2 performs to new cohorts)
  - both models should outperform M3 in all cohorts
  - also evaluate M1 after step 1
-> hypothesis: (1) is AOTA for specific speaker and (2) is better in generalizing (maybe even to unseen cohorts)

(3) Approach
- goal: train model that outperforms (2) and generalizes to unseen cohorts
- finetune whisper with hypermodel that generates LoRA weights
- insert LoRA weights with first layer of every feed forward network
- hypermodel
  - G: gating network generates weights for experts
  - E_i: Expert i. Expert for one type of atypical speech cohort. Each expert generates latent reprenstation of speech.
  - z: latent represenation of speech. weighted sum of of each expert
- training
  - fit GMM to data
  - train G to resemble GMM
  - freeze G and train experts 
  - train G and experts jointly

Data requirements
- dataset with: 
  - illness (cohort) information 
  - speaker id -> we need to finetune (1) to specific speaker
  - audio to text data
- if we don'T find such a dataset we could try to create our own (a lot of work) or group the speech samples in some other way.


Possible Datasets
- UA Speech  
  - need to contact over mail
- RAWDysPeech (https://data.mendeley.com/datasets/3mhnr7frht/1)
  - only has cohort information healthy / unhealthy
  - combination of TORGO, UASPEECH, Ultrax, EasyCall
- HeyJay (https://www.icpsr.umich.edu/web/ICPSR/studies/39448)
  - would be perfect but probably no access
  - see "access restricted data"
- Disordered speech sentences database (https://www.seeingspeech.ac.uk/speechstar/disordered-speech-sentences-database/)
  - scottisch children
  - contains cohort information and speaker id
  - small
- TORGO (https://www.cs.toronto.edu/~complingweb/data/TORGO/torgo.html)
  - 747 utterances of 8 Speaker (3F + 5M)
  - no cohorts
  - speaker id
- EasyCall
  - 


Full pipeline (cascaded)
- audio > ASR model > text > MT model > text






TORGO
├─ F
│  ├─ F01
│  │  └─ Session1
│  │     ├─ phn_arrayMic
│  │     ├─ prompts
│  │     └─ wav_headMic
│  ├─ F03
│  │  ├─ Session1
│  │  │  ├─ phn_arrayMic
│  │  │  ├─ prompts
│  │  │  └─ wav_headMic
│  │  ├─ Session2
│  │  │  ├─ phn_headMic
│  │  │  ├─ prompts
│  │  │  └─ wav_headMic
│  │  └─ Session3
│  │     ├─ phn_headMic
│  │     ├─ prompts
│  │     └─ wav_headMic
│  └─ F04
│     ├─ Session1
│     │  ├─ prompts
│     │  └─ wav_arrayMic
│     └─ Session2
│        ├─ phn_headMic
│        ├─ prompts
│        └─ wav_headMic
└─ M
   ├─ M01
   │  ├─ Session1
   │  │  ├─ phn_headMic
   │  │  ├─ prompts
   │  │  └─ wav_headMic
   │  └─ Session2_3
   │     ├─ phn_arrayMic
   │     ├─ prompts
   │     └─ wav_headMic
   ├─ M02
   │  ├─ Session1
   │  │  ├─ phn_arrayMic
   │  │  ├─ prompts
   │  │  └─ wav_headMic
   │  └─ Session2
   │     ├─ phn_arrayMic
   │     ├─ prompts
   │     └─ wav_headMic
   ├─ M03
   │  └─ Session2
   │     ├─ prompts
   │     └─ wav_headMic
   ├─ M04
   │  ├─ Session1
   │  │  ├─ phn_arrayMic
   │  │  ├─ prompts
   │  │  └─ wav_arrayMic
   │  └─ Session2
   │     ├─ phn_headMic
   │     ├─ prompts
   │     └─ wav_headMic
   └─ M05
      ├─ Session1
      │  ├─ phn_headMic
      │  ├─ prompts
      │  └─ wav_headMic
      └─ Session2
         ├─ phn_headMic
         ├─ prompts
         └─ wav_headMic